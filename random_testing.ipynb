{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf9af23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rauna\\Anaconda3\\envs\\local_llm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial RAM usage: 218.82 MB\n",
      "RAM usage after loading model: 571.23 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import os\n",
    "\n",
    "def get_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss / (1024 ** 2)  # Convert bytes to MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4393084b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.124439808"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.num_parameters())/10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29bcccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0098d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03de50c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = psutil.Process(os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e1820dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "835.43359375"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.memory_info().rss/(1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "897163b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rauna\\Anaconda3\\envs\\local_llm\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\rauna\\.cache\\huggingface\\hub\\models--gpt2-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7c84115",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a49bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Harry Potter is about to face his biggest enemy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bbc6932",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(prompt, return_tensors='pt').input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f17a0b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, torch.Size([1, 9]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompt.split(' ')), input_ids.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbfb9753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5min 37s\n",
      "Wall time: 40.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gen_tokens = model.generate(input_ids, do_sample=True, temperature=2.0, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bb7b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_text = tokenizer.batch_decode(gen_tokens)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "404146d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter is about to face his biggest enemy as the entire student body is thrown into a panicked race on an all-time nightmare of Death Eaters killing one after the other - or dying. On their darkest possible night Gryffindors turn back. On the most hopeful ending Ravenclains turn in the brightest colours to claim victories.\" Dumbledore smiled to himself after his head became clouded. A cold silence filled the halls of Hogwarts followed by Harry looking out the window of Draco Potter's bed just\n"
     ]
    }
   ],
   "source": [
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1c936fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter is about to face his biggest enemy to date.\n",
      "\n",
      "Harry Potter and the Deathly Hallows, the eighth film in the world-wide blockbuster franchise that will be filmed in a total of three countries, and released in the United States on November 18, will be released nationwide on November 22.\n",
      "\n",
      "According to the official press release, the film will have over three hours of content, including a 15-minute prequel, a 20-minute standalone film and the Harry Potter and\n"
     ]
    }
   ],
   "source": [
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fb8529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "local_llm",
   "language": "python",
   "name": "local_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
